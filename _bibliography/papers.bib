------
2024
------

@article{davidson2024evaluating,
      title={Evaluating Language Model Agency through Negotiations},
      author={Tim R. Davidson and
              Veniamin Veselovsky and
              Martin Josifoski and
              Maxime Peyrard and
              Antoine Bosselut and
              Michal Kosinski and
              Robert West},
      year={2024},
      journal={ICLR},
      arxiv={2401.04536},
      pdf={davidson2024evaluating.pdf},
      code={https://github.com/epfl-dlab/LAMEN},
      preview={davidson2024evaluating_preview.png},
      bibtex_show={true}
}

@article{monea2023glitch,
      title={A Glitch in the Matrix? Locating and Detecting Language Model Grounding with Fakepedia},
      author={Giovanni Monea and Maxime Peyrard and Martin Josifoski and Vishrav Chaudhary and Jason Eisner and Emre Kıcıman and Hamid Palangi and Barun Patra and Robert West},
      year={2023},
      eprint={2312.02073},
      archivePrefix={arXiv},
      selected={true},
      arxiv={2312.02073},
      primaryClass={cs.CL},
      pdf={monea2023glitch.pdf},
      preview={monea2023glitch_preview.png},
      bibtex_show={true}
}

------
2023
------

@article{josifoski2023flows,
      title={Flows: Building Blocks of Reasoning and Collaborating AI},
      author={Martin Josifoski and Lars Klein and Maxime Peyrard and Yifei Li and Saibo Geng and Julian Paul Schnitzler and Yuxing Yao and Jiheng Wei and Debjit Paul and Robert West},
      year={2023},
      eprint={2308.01285},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      pdf={aiflows.pdf},
      selected={true},
      arxiv={2308.01285},
      code={https://github.com/epfl-dlab/aiflows},
      preview={aiflows_preview.png},
      bibtex_show={true}
}

@inproceedings{geng2023grammarconstrained,
      title={Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning},
      author={Saibo Geng and Martin Josifosky and Maxime Peyrard and Robert West},
      booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
      year = {2023},
      address = {Singapore},
      publisher = {Association for Computational Linguistics},
      url = {https://aclanthology.org/2023.emnlp-main.674},
      doi = {10.18653/v1/2023.emnlp-main.674},
      pages = {10932--10952},
      eprint={2305.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      arxiv={2305.13971},
      code={https://github.com/epfl-dlab/GCD},
      pdf={gcd.pdf},
      preview={gcd_preview.png},
      bibtex_show={true}
}

@inproceedings{šakota2023flyswat,
      title={Fly-Swat or Cannon? Cost-Effective Language Model Choice via Meta-Modeling},
      author={Marija Šakota and Maxime Peyrard and Robert West},
      booktitle={Proceedings of The International ACM Conference on Web Search and Data Mining (WSDM)},
      year={2023},
      eprint={2308.06077},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      arxiv={2308.06077},
      code={https://github.com/epfl-dlab/forc},
      pdf={metamodels.pdf},
      preview={metamodels_preview.png},
      bibtex_show={true}
}

@inproceedings{josifoski-etal-2023-exploiting,
    title = "Exploiting Asymmetry for Synthetic Training Data Generation: {S}ynth{IE} and the Case of Information Extraction",
    author = "Josifoski, Martin  and
      Sakota, Marija  and
      Peyrard, Maxime  and
      West, Robert",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.96",
    doi = "10.18653/v1/2023.emnlp-main.96",
    pages = "1555--1574",
    arxiv={2303.04132},
    code={https://github.com/epfl-dlab/SynthIE},
    pdf={synthie.pdf},
    preview={synthie_preview.png},
    bibtex_show={true}
}

@misc{paul2023refiner,
  title={REFINER: Reasoning Feedback on Intermediate Representations},
  author={Paul, Debjit and Ismayilzada, Mete and Peyrard, Maxime and Borges, Beatriz and Bosselut, Antoine and West, Robert and Faltings, Boi},
  eprint={2304.01904},
  journal={arXiv preprint arXiv:2304.01904},
  url={https://arxiv.org/pdf/2304.01904.pdf},
  year={2023},
  arxiv={2304.01904},
  code={https://github.com/debjitpaul/refiner},
  pdf={refiner.pdf},
  selected={true},
  preview={refiner_preview.png},
  bibtex_show={true}
}

@inproceedings{10.1145/3543507.3583220,
  author = {Sakota, Marija and Peyrard, Maxime and West, Robert},
  title = {Descartes: Generating Short Descriptions of Wikipedia Articles},
  year = {2023},
  booktitle={Proceedings of The Web Conference (WWW)},
  isbn = {9781450394161},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3543507.3583220},
  doi = {10.1145/3543507.3583220},
  pages = {1446–1456},
  arxiv={2205.10012},
  code={https://github.com/epfl-dlab/descartes},
  pdf={descartes.pdf},
  preview={descartes_preview.png},
  bibtex_show={true}
}

@INPROCEEDINGS {10136150,
  author = {V. Hartmann and L. Meynent and M. Peyrard and D. Dimitriadis and S. Tople and R. West},
  booktitle = {2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)},
  title = {Distribution Inference Risks: Identifying and Mitigating Sources of Leakage},
  year = {2023},
  volume = {},
  issn = {},
  pages = {136-149},
  abstract = {A large body of work shows that machine learning (ML) models can leak sensitive or confidential information about their training data. Recently, leakage due to distribution inference (or property inference) attacks is gaining attention. In this attack, the goal of an adversary is to infer distributional information about the training data. So far, research on distribution inference has focused on demonstrating successful attacks, with little attention given to identifying the potential causes of the leakage and to proposing mitigations. To bridge this gap, as our main contribution, we theoretically and empirically analyze the sources of information leakage that allows an adversary to perpetrate distribution inference attacks. We identify three sources of leakage: (1) memorizing specific information about the $\mathbb{E}[Y\vert X]$ (expected label given the feature values) of interest to the adversary, (2) wrong inductive bias of the model, and (3) finiteness of the training data. Next, based on our analysis, we propose principled mitigation techniques against distribution inference attacks. Specifically, we demonstrate that causal learning techniques are more resilient to a particular type of distribution inference risk termed distributional membership inference than associative learning methods. And lastly, we present a formalization of distribution inference that allows for reasoning about more general adversaries than was previously possible.},
  keywords = {learning systems;training;bridges;training data;machine learning;data models;libraries},
  doi = {10.1109/SaTML54575.2023.00018},
  url = {https://doi.ieeecomputersociety.org/10.1109/SaTML54575.2023.00018},
  arxiv={2209.08541},
  code={https://github.com/epfl-dlab/distribution-inference-risks},
  pdf={dist_inf.pdf},
  preview={dist_inf_preview.png},
  bibtex_show={true}
}

@inproceedings{josifoski-etal-2023-language,
    title = "Language Model Decoding as Likelihood{--}Utility Alignment",
    author = "Josifoski, Martin  and
      Peyrard, Maxime  and
      Raji{\v{c}}, Frano  and
      Wei, Jiheng  and
      Paul, Debjit  and
      Hartmann, Valentin  and
      Patra, Barun  and
      Chaudhary, Vishrav  and
      Kiciman, Emre  and
      Faltings, Boi",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2023",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-eacl.107",
    doi = "10.18653/v1/2023.findings-eacl.107",
    pages = "1455--1470",
    abstract = "A critical component of a successful language generation pipeline is the decoding algorithm. However, the general principles that should guide the choice of a decoding algorithm remain unclear. Previous works only compare decoding algorithms in narrow scenarios, and their findings do not generalize across tasks. We argue that the misalignment between the model{'}s likelihood and the task-specific notion of utility is the key factor in understanding the effectiveness of decoding algorithms. To structure the discussion, we introduce a taxonomy of misalignment mitigation strategies (MMSs), providing a unifying view of decoding as a tool for alignment. The MMS taxonomy groups decoding algorithms based on their implicit assumptions about likelihood{--}utility misalignment, yielding general statements about their applicability across tasks. Specifically, by analyzing the correlation between the likelihood and the utility of predictions across a diverse set of tasks, we provide empirical evidence supporting the proposed taxonomy and a set of principles to structure reasoning when choosing a decoding algorithm. Crucially, our analysis is the first to relate likelihood-based decoding algorithms with algorithms that rely on external information, such as value-guided methods and prompting, and covers the most diverse set of tasks to date. Code, data, and models are available at \url{https://github.com/epfl-dlab/understanding-decoding}.",
    arxiv={2210.07228},
    code={https://github.com/epfl-dlab/understanding-decoding},
    pdf={likelihood.pdf},
    preview={likelihood_preview.png},
    bibtex_show={true}
}

------
2022
------

@misc{colombo2022glass,
      title={The Glass Ceiling of Automatic Evaluation in Natural Language Generation},
      author={Pierre Colombo and Maxime Peyrard and Nathan Noiry and Robert West and Pablo Piantanida},
      year={2022},
      eprint={2208.14585},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{peyrard-etal-2022-invariant,
    title = "Invariant Language Modeling",
    author = "Peyrard, Maxime  and
      Ghotra, Sarvjeet  and
      Josifoski, Martin  and
      Agarwal, Vidhan  and
      Patra, Barun  and
      Carignan, Dean  and
      Kiciman, Emre  and
      Tiwary, Saurabh  and
      West, Robert",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.387",
    doi = "10.18653/v1/2022.emnlp-main.387",
    pages = "5728--5743",
    abstract = "Modern pretrained language models are critical components of NLP pipelines. Yet, they suffer from spurious correlations, poor out-of-domain generalization, and biases. Inspired by recent progress in causal machine learning, in particular the invariant risk minimization (IRM) paradigm, we propose invariant language modeling, a framework for learning invariant representations that generalize better across multiple environments. In particular, we adapt a game-theoretic implementation of IRM (IRM-games) to language models, where the invariance emerges from a specific training schedule in which all the environments compete to optimize their own environment-specific loss by updating subsets of the model in a round-robin fashion. We focused on controlled experiments to precisely demonstrate the ability of our method to (i) remove structured noise, (ii) ignore specific spurious correlations without affecting global performance, and (iii) achieve better out-of-domain generalization. These benefits come with a negligible computational overhead compared to standard training, do not require changing the local loss, and can be applied to any language model. We believe this framework is promising to help mitigate spurious correlations and biases in language models.",
}

@inproceedings{DBLP:conf/icwsm/CzestochowskaGP22,
  author       = {Justyna Czestochowska and
                  Kristina Gligoric and
                  Maxime Peyrard and
                  Yann Mentha and
                  Michal Bien and
                  Andrea Gr{\"{u}}tter and
                  Anita Auer and
                  Aris Xanthos and
                  Robert West},
  editor       = {Ceren Budak and
                  Meeyoung Cha and
                  Daniele Quercia},
  title        = {On the Context-Free Ambiguity of Emoji},
  booktitle    = {Proceedings of the Sixteenth International {AAAI} Conference on Web
                  and Social Media, {ICWSM} 2022, Atlanta, Georgia, USA, June 6-9, 2022},
  pages        = {1388--1392},
  publisher    = {{AAAI} Press},
  year         = {2022},
  url          = {https://ojs.aaai.org/index.php/ICWSM/article/view/19393},
  timestamp    = {Wed, 22 Jun 2022 16:52:45 +0200},
  biburl       = {https://dblp.org/rec/conf/icwsm/CzestochowskaGP22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.1007/978-3-031-20050-2_27,
  author = {Teney, Damien and Peyrard, Maxime and Abbasnejad, Ehsan},
  title = {Predicting Is Not Understanding: Recognizing And Addressing Underspecification In Machine Learning},
  year = {2022},
  isbn = {978-3-031-20049-6},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  url = {https://doi.org/10.1007/978-3-031-20050-2_27},
  doi = {10.1007/978-3-031-20050-2_27},
  abstract = {Machine learning (ML) models are typically optimized for their accuracy on a given dataset. However, this predictive criterion rarely captures all desirable properties of a model, in particular how well it matches a domain expert’s understanding of a task. Underspecification [6] refers to the existence of multiple models that are indistinguishable in their in-domain accuracy, even though they differ in other desirable properties such as out-of-distribution (OOD) performance. Identifying these situations is critical for assessing the reliability of ML models. We formalize the concept of underspecification and propose a method to identify and partially address it. We train multiple models with an independence constraint that forces them to implement different functions. They discover predictive features that are otherwise ignored by standard empirical risk minimization (ERM), which we then distill into a global model with superior OOD performance. Importantly, we constrain the models to align with the data manifold to ensure that they discover meaningful features. We demonstrate the method on multiple datasets in computer vision (collages, WILDS-Camelyon17, GQA) and discuss general implications of underspecification. Most notably, in-domain performance cannot serve for OOD model selection without additional assumptions (See for the full-length version of this work).},
  booktitle = {Computer Vision – ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part XXIII},
  pages = {458–476},
  numpages = {19},
  location = {Tel Aviv, Israel}
}

@inproceedings{josifoski-etal-2022-genie,
    title = "{G}en{IE}: Generative Information Extraction",
    author = "Josifoski, Martin  and
      De Cao, Nicola  and
      Peyrard, Maxime  and
      Petroni, Fabio  and
      West, Robert",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.342",
    doi = "10.18653/v1/2022.naacl-main.342",
    pages = "4626--4643",
    abstract = "Structured and grounded representation of text is typically formalized by closed information extraction, the problem of extracting an exhaustive set of (subject, relation, object) triplets that are consistent with a predefined set of entities and relations from a knowledge base schema. Most existing works are pipelines prone to error accumulation, and all approaches are only applicable to unrealistically small numbers of entities and relations. We introduce GenIE (generative information extraction), the first end-to-end autoregressive formulation of closed information extraction. GenIE naturally exploits the language knowledge from the pre-trained transformer by autoregressively generating relations and entities in textual form. Thanks to a new bi-level constrained generation strategy, only triplets consistent with the predefined knowledge base schema are produced. Our experiments show that GenIE is state-of-the-art on closed information extraction, generalizes from fewer training data points than baselines, and scales to a previously unmanageable number of entities and relations. With this work, closed information extraction becomes practical in realistic scenarios, providing new opportunities for downstream tasks. Finally, this work paves the way towards a unified end-to-end approach to the core tasks of information extraction.",
}

------
2021
------

@inproceedings{Peyrard2021LaughingHC,
  title={Laughing Heads: Can Transformers Detect What Makes a Sentence Funny?},
  author={Maxime Peyrard and Beatriz Borges and Kristina Gligoric and Robert West},
  booktitle={International Joint Conference on Artificial Intelligence},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:234778118}
}

@inproceedings{peyrard-etal-2021-better,
    title = "Better than Average: Paired Evaluation of {NLP} systems",
    author = "Peyrard, Maxime  and
      Zhao, Wei  and
      Eger, Steffen  and
      West, Robert",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.179",
    doi = "10.18653/v1/2021.acl-long.179",
    pages = "2301--2315",
    abstract = "Evaluation in NLP is usually done by comparing the scores of competing systems independently averaged over a common set of test instances. In this work, we question the use of averages for aggregating evaluation scores into a final number used to decide which system is best, since the average, as well as alternatives such as the median, ignores the pairing arising from the fact that systems are evaluated on the same test instances. We illustrate the importance of taking the instancelevel pairing of evaluation scores into account and demonstrate, both theoretically and empirically, the advantages of aggregation methods based on pairwise comparisons, such as the Bradley{--}Terry (BT) model, a mechanism based on the estimated probability that a given system scores better than another on the test set. By re-evaluating 296 real NLP evaluation setups across four tasks and 18 evaluation metrics, we show that the choice of aggregation mechanism matters and yields different conclusions as to which systems are state of the art in about 30{\%} of the setups. To facilitate the adoption of pairwise evaluation, we release a practical tool for performing the full analysis of evaluation scores with the mean, median, BT, and two variants of BT (Elo and TrueSkill), alongside functionality for appropriate statistical testing.",
}

@article{ribeiro2021sudden,
  title={Sudden Attention Shifts on Wikipedia Following COVID-19 Mobility Restrictions},
  author={Ribeiro, Manoel Horta and Gligori{\'c}, Kristina and Peyrard, Maxime
          and Lemmerich, Florian and Strohmaier, Markus and West, Robert},
  booktitle = {Proceedings of the 15th International AAAI
               Conference on Weblogs and Social Media (ICWSM'21)},
  year={2021},
  abstract={We study how the COVID-19 pandemic, alongside the severe mobility restrictions that ensued, has impacted information access on Wikipedia, the world's largest online encyclopedia. A longitudinal analysis that combines pageview statistics for 12 Wikipedia language editions with mobility reports published by Apple and Google reveals massive shifts in the volume and nature of information seeking patterns during the pandemic. Interestingly, while we observe a transient increase in Wikipedia's pageview volume following mobility restrictions, the nature of information sought was impacted more permanently. These changes are most pronounced for language editions associated with countries where the most severe mobility restrictions were implemented. We also find that articles belonging to different topics behaved differently; e.g., attention towards entertainment-related topics is lingering and even increasing, while the interest in health- and biology-related topics was either small or transient. Our results highlight the utility of Wikipedia for studying how the pandemic is affecting people's needs, interests, and concerns.}
}

------
2020
------

@inproceedings{peyrard-west-2020-klearn,
    title = "{KL}earn: Background Knowledge Inference from Summarization Data",
    author = "Peyrard, Maxime  and
      West, Robert",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.188",
    doi = "10.18653/v1/2020.findings-emnlp.188",
    pages = "2073--2085",
    abstract = "The goal of text summarization is to compress documents to the relevant information while excluding background information already known to the receiver. So far, summarization researchers have given considerably more attention to relevance than to background knowledge. In contrast, this work puts background knowledge in the foreground. Building on the realization that the choices made by human summarizers and annotators contain implicit information about their background knowledge, we develop and compare techniques for inferring background knowledge from summarization data. Based on this framework, we define summary scoring functions that explicitly model background knowledge, and show that these scoring functions fit human judgments significantly better than baselines. We illustrate some of the many potential applications of our framework. First, we provide insights into human information importance priors. Second, we demonstrate that averaging the background knowledge of multiple, potentially biased annotators or corpora greatly improves summaryscoring performance. Finally, we discuss potential applications of our framework beyond summarization.",
}

@misc{gligorić2020experts,
      title={Experts and authorities receive disproportionate attention on Twitter during the COVID-19 crisis},
      author={Kristina Gligorić and Manoel Horta Ribeiro and Martin Müller and Olesia Altunina and Maxime Peyrard and Marcel Salathé and Giovanni Colavizza and Robert West},
      year={2020},
      eprint={2008.08364},
      archivePrefix={arXiv},
      primaryClass={cs.SI}
}

@inproceedings{zhao-etal-2020-limitations,
    title = "On the Limitations of Cross-lingual Encoders as Exposed by Reference-Free Machine Translation Evaluation",
    author = "Zhao, Wei  and
      Glava{\v{s}}, Goran  and
      Peyrard, Maxime  and
      Gao, Yang  and
      West, Robert  and
      Eger, Steffen",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.151",
    doi = "10.18653/v1/2020.acl-main.151",
    pages = "1656--1671",
    abstract = "Evaluation of cross-lingual encoders is usually performed either via zero-shot cross-lingual transfer in supervised downstream tasks or via unsupervised cross-lingual textual similarity. In this paper, we concern ourselves with reference-free machine translation (MT) evaluation where we directly compare source texts to (sometimes low-quality) system translations, which represents a natural adversarial setup for multilingual encoders. Reference-free evaluation holds the promise of web-scale comparison of MT systems. We systematically investigate a range of metrics based on state-of-the-art cross-lingual semantic representations obtained with pretrained M-BERT and LASER. We find that they perform poorly as semantic encoders for reference-free MT evaluation and identify their two key limitations, namely, (a) a semantic mismatch between representations of mutual translations and, more prominently, (b) the inability to punish {``}translationese{''}, i.e., low-quality literal translations. We propose two partial remedies: (1) post-hoc re-alignment of the vector spaces and (2) coupling of semantic-similarity based metrics with target-side language modeling. In segment-level MT evaluation, our best metric surpasses reference-based BLEU by 5.7 correlation points.",
}

@inproceedings{Peyrard2020ALO,
  title={A Ladder of Causal Distances},
  author={Maxime Peyrard and Robert West},
  booktitle={International Joint Conference on Artificial Intelligence},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:218517016}
}

------
2019
------

@inproceedings{zhao-etal-2019-moverscore,
    title = "{M}over{S}core: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance",
    author = "Zhao, Wei  and
      Peyrard, Maxime  and
      Liu, Fei  and
      Gao, Yang  and
      Meyer, Christian M.  and
      Eger, Steffen",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1053",
    doi = "10.18653/v1/D19-1053",
    pages = "563--578",
    abstract = "A robust evaluation metric has a profound impact on the development of text generation systems. A desirable metric compares system output against references based on their semantics rather than surface forms. In this paper we investigate strategies to encode system and reference texts to devise a metric that shows a high correlation with human judgment of text quality. We validate our new metric, namely MoverScore, on a number of text generation tasks including summarization, machine translation, image captioning, and data-to-text generation, where the outputs are produced by a variety of neural and non-neural systems. Our findings suggest that metrics combining contextualized representations with a distance measure perform the best. Such metrics also demonstrate strong generalization capability across tasks. For ease-of-use we make our metrics available as web service.",
}

@inproceedings{peyrard-2019-simple,
    title = "A Simple Theoretical Model of Importance for Summarization",
    author = "Peyrard, Maxime",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1101",
    doi = "10.18653/v1/P19-1101",
    pages = "1059--1073",
    abstract = "Research on summarization has mainly been driven by empirical approaches, crafting systems to perform well on standard datasets with the notion of information Importance remaining latent. We argue that establishing theoretical models of Importance will advance our understanding of the task and help to further improve summarization systems. To this end, we propose simple but rigorous definitions of several concepts that were previously used only intuitively in summarization: Redundancy, Relevance, and Informativeness. Importance arises as a single quantity naturally unifying these concepts. Additionally, we provide intuitions to interpret the proposed quantities and experiments to demonstrate the potential of the framework to inform and guide subsequent works.",
}

@inproceedings{peyrard-2019-studying,
    title = "Studying Summarization Evaluation Metrics in the Appropriate Scoring Range",
    author = "Peyrard, Maxime",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1502",
    doi = "10.18653/v1/P19-1502",
    pages = "5093--5100",
    abstract = "In summarization, automatic evaluation metrics are usually compared based on their ability to correlate with human judgments. Unfortunately, the few existing human judgment datasets have been created as by-products of the manual evaluations performed during the DUC/TAC shared tasks. However, modern systems are typically better than the best systems submitted at the time of these shared tasks. We show that, surprisingly, evaluation metrics which behave similarly on these datasets (average-scoring range) strongly disagree in the higher-scoring range in which current systems now operate. It is problematic because metrics disagree yet we can{'}t decide which one to trust. This is a call for collecting human judgments for high-scoring summaries as this would resolve the debate over which metrics to trust. This would also be greatly beneficial to further improve summarization systems and metrics alike.",
}

------
2018
------

@inproceedings{p-v-s-etal-2018-live,
    title = "Live Blog Corpus for Summarization",
    author = "P.V.S., Avinesh  and
      Peyrard, Maxime  and
      Meyer, Christian M.",
    booktitle = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)",
    month = may,
    year = "2018",
    address = "Miyazaki, Japan",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L18-1505",
}

@article{rueckle:2018,
  title = {Concatenated Power Mean Word Embeddings as Universal Cross-Lingual Sentence Representations},
  author = {R{\"u}ckl{\'e}, Andreas and Eger, Steffen and Peyrard, Maxime and Gurevych, Iryna},
  journal = {arXiv},
  year = {2018},
  url = "https://arxiv.org/abs/1803.01400"
}

@inproceedings{peyrard-gurevych-2018-objective,
    title = "Objective Function Learning to Match Human Judgements for Optimization-Based Summarization",
    author = "Peyrard, Maxime  and
      Gurevych, Iryna",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-2103",
    doi = "10.18653/v1/N18-2103",
    pages = "654--660",
    abstract = "Supervised summarization systems usually rely on supervision at the sentence or n-gram level provided by automatic metrics like ROUGE, which act as noisy proxies for human judgments. In this work, we learn a summary-level scoring function $\theta$ including human judgments as supervision and automatically generated data as regularization. We extract summaries with a genetic algorithm using $\theta$ as a fitness function. We observe strong and promising performances across datasets in both automatic and manual evaluation.",
}

------
2017
------

@inproceedings{peyrard-eckle-kohler-2017-principled,
    title = "A Principled Framework for Evaluating Summarizers: Comparing Models of Summary Quality against Human Judgments",
    author = "Peyrard, Maxime  and
      Eckle-Kohler, Judith",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-2005",
    doi = "10.18653/v1/P17-2005",
    pages = "26--31",
    abstract = "We present a new framework for evaluating extractive summarizers, which is based on a principled representation as optimization problem. We prove that every extractive summarizer can be decomposed into an objective function and an optimization technique. We perform a comparative analysis and evaluation of several objective functions embedded in well-known summarizers regarding their correlation with human judgments. Our comparison of these correlations across two datasets yields surprising insights into the role and performance of objective functions in the different summarizers.",
}

@inproceedings{peyrard-etal-2017-learning,
    title = "Learning to Score System Summaries for Better Content Selection Evaluation.",
    author = "Peyrard, Maxime  and
      Botschen, Teresa  and
      Gurevych, Iryna",
    booktitle = "Proceedings of the Workshop on New Frontiers in Summarization",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-4510",
    doi = "10.18653/v1/W17-4510",
    pages = "74--84",
    abstract = "The evaluation of summaries is a challenging but crucial task of the summarization field. In this work, we propose to learn an automatic scoring metric based on the human judgements available as part of classical summarization datasets like TAC-2008 and TAC-2009. Any existing automatic scoring metrics can be included as features, the model learns the combination exhibiting the best correlation with human judgments. The reliability of the new metric is tested in a further manual evaluation where we ask humans to evaluate summaries covering the whole scoring spectrum of the metric. We release the trained metric as an open-source tool.",
}

@inproceedings{peyrard-eckle-kohler-2017-supervised,
    title = "Supervised Learning of Automatic Pyramid for Optimization-Based Multi-Document Summarization",
    author = "Peyrard, Maxime  and
      Eckle-Kohler, Judith",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1100",
    doi = "10.18653/v1/P17-1100",
    pages = "1084--1094",
    abstract = "We present a new supervised framework that learns to estimate automatic Pyramid scores and uses them for optimization-based extractive multi-document summarization. For learning automatic Pyramid scores, we developed a method for automatic training data generation which is based on a genetic algorithm using automatic Pyramid as the fitness function. Our experimental evaluation shows that our new framework significantly outperforms strong baselines regarding automatic Pyramid, and that there is much room for improvement in comparison with the upper-bound for automatic Pyramid.",
}

@inproceedings{bugert-etal-2017-lsdsem,
    title = "{LSDS}em 2017: Exploring Data Generation Methods for the Story Cloze Test",
    author = {Bugert, Michael  and
      Puzikov, Yevgeniy  and
      R{\"u}ckl{\'e}, Andreas  and
      Eckle-Kohler, Judith  and
      Martin, Teresa  and
      Mart{\'\i}nez-C{\'a}mara, Eugenio  and
      Sorokin, Daniil  and
      Peyrard, Maxime  and
      Gurevych, Iryna},
    booktitle = "Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-0908",
    doi = "10.18653/v1/W17-0908",
    pages = "56--61",
    abstract = "The Story Cloze test is a recent effort in providing a common test scenario for text understanding systems. As part of the LSDSem 2017 shared task, we present a system based on a deep learning architecture combined with a rich set of manually-crafted linguistic features. The system outperforms all known baselines for the task, suggesting that the chosen approach is promising. We additionally present two methods for generating further training data based on stories from the ROCStories corpus.",
}

------
2016
------

@inproceedings{zopf-etal-2016-next,
    title = "The Next Step for Multi-Document Summarization: A Heterogeneous Multi-Genre Corpus Built with a Novel Construction Approach",
    author = "Zopf, Markus  and
      Peyrard, Maxime  and
      Eckle-Kohler, Judith",
    booktitle = "Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",
    month = dec,
    year = "2016",
    address = "Osaka, Japan",
    publisher = "The COLING 2016 Organizing Committee",
    url = "https://aclanthology.org/C16-1145",
    pages = "1535--1545",
    abstract = "Research in multi-document summarization has focused on newswire corpora since the early beginnings. However, the newswire genre provides genre-specific features such as sentence position which are easy to exploit in summarization systems. Such easy to exploit genre-specific features are available in other genres as well. We therefore present the new hMDS corpus for multi-document summarization, which contains heterogeneous source documents from multiple text genres, as well as summaries with different lengths. For the construction of the corpus, we developed a novel construction approach which is suited to build large and heterogeneous summarization corpora with little effort. The method reverses the usual process of writing summaries for given source documents: it combines already available summaries with appropriate source documents. In a detailed analysis, we show that our new corpus is significantly different from the homogeneous corpora commonly used, and that it is heterogeneous along several dimensions. Our experimental evaluation using well-known state-of-the-art summarization systems shows that our corpus poses new challenges in the field of multi-document summarization. Last but not least, we make our corpus publicly available to the research community at the corpus web page \url{https://github.com/AIPHES/hMDS}.",
}

@inproceedings{peyrard-eckle-kohler-2016-general,
    title = "A General Optimization Framework for Multi-Document Summarization Using Genetic Algorithms and Swarm Intelligence",
    author = "Peyrard, Maxime  and
      Eckle-Kohler, Judith",
    booktitle = "Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",
    month = dec,
    year = "2016",
    address = "Osaka, Japan",
    publisher = "The COLING 2016 Organizing Committee",
    url = "https://aclanthology.org/C16-1024",
    pages = "247--257",
    abstract = "Extracting summaries via integer linear programming and submodularity are popular and successful techniques in extractive multi-document summarization. However, many interesting optimization objectives are neither submodular nor factorizable into an integer linear program. We address this issue and present a general optimization framework where any function of input documents and a system summary can be plugged in. Our framework includes two kinds of summarizers {--} one based on genetic algorithms, the other using a swarm intelligence approach. In our experimental evaluation, we investigate the optimization of two information-theoretic summary evaluation metrics and find that our framework yields competitive results compared to several strong summarization baselines. Our comparative analysis of the genetic and swarm summarizers reveals interesting complementary properties.",
}

@inproceedings{peyrard-eckle-kohler-2016-optimizing,
    title = "Optimizing an Approximation of {ROUGE} - a Problem-Reduction Approach to Extractive Multi-Document Summarization",
    author = "Peyrard, Maxime  and
      Eckle-Kohler, Judith",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1172",
    doi = "10.18653/v1/P16-1172",
    pages = "1825--1836",
}
